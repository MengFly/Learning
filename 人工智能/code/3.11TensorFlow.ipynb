{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "假设你有一个损失函数J需要最小化，你会怎么办？\n",
    "    在这个例子中，我们使用一个简单的例子，即\\\\(J(w)=w^2-10w+25\\\\),这就是损失函数。其实这个函数就是\\\\(J=(w-5)^2\\\\),但是假设我们不知道这点，你只有上面第一个函数，我们来看一下怎么用TensorFlow将其最小化。类似的，我们就可以用TensorFlow自动找到损失函数最小的w和b的值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "w = tf.Variable(0, dtype=tf.float32) #tensorflow中，我们使用Variable来设置变量\n",
    "cost = tf.add(tf.add(w**2, tf.multiply(-10., w)),25) # 定义损失函数\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)#定义学习算法\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "session = tf.Session()\n",
    "session.run(init)\n",
    "print(session.run(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n"
     ]
    }
   ],
   "source": [
    "session.run(train) # 运行一次梯度下降法\n",
    "print(session.run(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.99999\n"
     ]
    }
   ],
   "source": [
    "# 运行1000次学习算法\n",
    "for i in range(1000):\n",
    "    session.run(train)\n",
    "print(session.run(w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "所以，在运行1000次优化算法后，我们发现，最终的到的w值已经非常接近我们的最优值了，我们其实知道最优值是5.0。这里，w是我们想要优化的参数，因此把它称之为变量，注意，我们需要做的就是定义一个损失函数，使用这些TensorFlow提供的基础运算的操作函数。TensorFlow知道如何对add和mutiply还有其他函数求导，这就是为什么你只需基本实现向前传播，他就能弄明白如何做反向传播和梯度计算。实际上，Tensorflow也重载了操作符，上面损失函数的定义也可以写作：\n",
    "```python\n",
    "cost = w**2 - 10*w + 25\n",
    "```\n",
    "结果是没有什么区别的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果，你想要最小化的函数是训练集函数又如何呢？不管你有什么训练数据x，当你训练神经网络的时候，训练数据x都会改变，如何把训练数据加入TensorFlow程序呢？\n",
    "这里，我们应该这么定义(我们重新定义一下变量）："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w = tf.Variable(0, dtype=tf.float32) #tensorflow中，我们使用Variable来设置变量\n",
    "x = tf.placeholder(dtype=tf.float32, shape=[3,1])\n",
    "cost = x[0][0]*w**2 + x[1][0]*w + x[2][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在，x变成了控制损失函数系数的数据。这个**placeholder**函数告诉TensorFlow我们稍后会给x提供数值。我们现在定义一组数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coefficient = np.array([[1.], [-10.], [25.]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最后，我们需要用某种方式把这个系数数组接入到变量x中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)#定义学习算法\n",
    "init = tf.global_variables_initializer()\n",
    "session = tf.Session()\n",
    "session.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.198\n"
     ]
    }
   ],
   "source": [
    "session.run(train, feed_dict={x:coefficient})\n",
    "print(session.run(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.99999\n"
     ]
    }
   ],
   "source": [
    "for i in range(1000):\n",
    "    session.run(train, feed_dict={x:coefficient})\n",
    "print(session.run(w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在，如果我们想要更换函数的系数的话就方便的多了。我们只需要改变向量x即可。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coefficient = np.array([[1.], [-20.], [100.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(1000):\n",
    "    session.run(train, feed_dict={x:coefficient})\n",
    "print(session.run(w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在做编程练习时见到更多的是，Tensorflow中的placeholder是一个我们之后会赋值的变量，这种方式便于把训练数据加入损失方程，把数据加入损失方程用的就是这个句法。\n",
    "如果你在做mini-batch梯度下降，在每次迭代时需要插入不同的mini-batch，那么每次迭代，我们就用feed_dict来喂入训练集不同的子集。 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "session.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
