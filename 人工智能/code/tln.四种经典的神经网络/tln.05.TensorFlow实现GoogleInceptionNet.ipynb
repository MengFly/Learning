{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GoogleInceptionNet\n",
    "+ **作者**：Google\n",
    "+ **特点**：控制了计算量和参数量的同时，获得了非常好的分类性能——top5 error rate 6.67%\n",
    " Inception V1有22层深，比AlexNet的8层或者VGGNet的19层还要深，但其计算量只有15一次浮点运算，只有500万参数，仅为AlexNet的1/12\n",
    " Inception V1 参数少但效果好的原因除了模型层数更深，表达能力更强外，还有两点：\n",
    "  1. 去除了最后的全连接层，用全局平均池化层（即将图片尺寸变为1x1来取代，全连接层几乎占据了AlexNet或者VGGNet90%的参数量。去除全连接层后模型训练更快并且减轻了过拟合。用全局平均池化层取代全连接层的做法借鉴了Network In NetWork论文）。\n",
    "  2. Inception V1中精心设计的InceptionModule提高了参数的利用率。InceptionModule本身如同大网络中的一个小网络，其结构可以反复堆叠在一起形成大网络。InceptionV1比NIN增加了分支 网络，NIN主要是级联的卷积层和MLPConv层，卷积层必须通过增加输出通道数提升表达能力，但是会导致计算量增大以及过拟合，每一个输出通道对应一个滤波器，同一个滤波器共享参数，只能提取一类特征，因此一个输出通道智能做一种特征处理。NIN中的MLPConv层拥有更强大的能力，允许在输出通道之间组合信息。MLPConv基本等效于普通卷积层后再链接1x1卷积核ReLU激活函数。\n",
    "+ **结构**：\n",
    " ![InceptionModule](img/InceptionModule.png)\n",
    " + 可以看到，Inception Module有四个分支：\n",
    "   1. 对输入进行1x1卷积,这也是NIN中提出的一个重要结构,可以跨通道组织信息，提高网络表达能力。同时还可以对输出通道升降维。Inception Module四个分支都用到了1x1卷积，来进行降低成本的跨通道的特征变换。\n",
    "   2. 先使用1x1卷积，再连接3x3卷积，相当于进行了两次特征变换\n",
    "   3. 和第二个分支类似，先1x1，再5x5\n",
    "   4. 3x3最大池化后直接使用1x1卷积。\n",
    "   可以看到，上面四个分支都使用了1x1卷积，这是因为1x1卷积性价比很高，用很少的计算量就能增加一层特征变换和非线性化。\n",
    "   + 最后有一个聚合操作。InceptionModule包含了3中不同尺寸的卷积以及一个最大池化，增加了网络对不同尺度的适应性。这一部分和Multi-Scale的思想类似。\n",
    "   早期ComputerVersion研究中，受灵长类神经视觉系统的启发，Serre使用不同尺寸的Gabor滤波器处理不同尺寸的图片，InceptionV1借鉴了这种思想，InceptionV1的论文中指出，InceptionModule可以让网络深度和宽度高效率扩充，提高准确率且不至于过拟合。\n",
    " \n",
    " 人脑神经元链接是稀疏的。研究者认为大型神经网络的合理链接方式也应是稀疏的，可以减轻过拟合并降低计算量，例如卷积神经网络就是稀疏的链接。InceptionNet目标就是找到最优的稀疏结构单元。其稀疏结构基于**Hebbian原理**：神经反射活动的持续与重复会导致神经元链接稳定性持久提升，“一起发射的神经元会连在一起，学习过程中的刺激会使神经元件的突触强度增加。”\n",
    " \n",
    " *Provable Bounds for Learning Some Deepp Representations*提出，如果数据集的概率分布可以被一个很大很稀疏的神经网络所表达，那么构筑这个网络的最佳方式是逐层构建网络，将上一层高度相关的节点聚类，并将聚类出来的每一个小簇连接到一起。\n",
    " ![6.11](img/6.11.png)\n",
    " \n",
    " 因此，好的稀疏结构应该符合*Hebbian*原理的。应该把相关性高的一簇神经元节点连接在一起。图片数据中，临近区域数据相关性高，因此相邻的像素点被卷及操作连接在一起。我们可能有多个卷积核，在**同一空间位置但在不同通道的卷积核输出结果相关性极高**，因此，一个1x1的卷积就可以很自然地把这些相关性很高的，在同一个空间位置但是不同通道的特征连接在一起。这就是频繁应用1x1卷积核的原因。\n",
    " 同理，3x3,5x5卷积连接的节点相关性也很高，因此添加一些大尺寸卷积，增加多样性，最后InceptionModule将相关性很高的节点连接在一起，就完成了设计初衷，构建出了很高效的符合Hebbian原理的稀疏结构。\n",
    " \n",
    " InceptionModule中，通常1x1卷积的输出通道占比会比较高。3x3和5x5占比稍低，因为我们希望靠后的InceptionModule可以捕捉高阶特征，因此靠后的卷积空间集中度应该较低，这样可以捕获大面积特征，因此，越靠后的InceptionModule中，3x3和5x5的卷积输出占比应该越高。\n",
    " \n",
    " InceptionNet有22层深，除了最后一层的输出，中间节点分类效果也很好，因此在InceptionNet中，还是用了辅助分类节点，将中间某一层的输出用作分类，按一个较小的权重（0.3）加到最终分类结果中。相当于做了模型融合，同时给网络增加了反向传播的梯度信号，也提供饿了额外的正则化。\n",
    "\n",
    "+ **成就**：ILSVRC2014比赛第一名\n",
    "\n",
    "+ **家族**\n",
    " 1. 2014.09 *Going Deeper with Convolutions* Inception V1(top5 error rate 6.67)\n",
    " 2. 2015.02 *Batch Normalization:Accelerating Deep Network Training by Reducing Internal Covariate* Inception V2(top5 error rate 4.8)\n",
    " 3. 2015.12 *Rethining the Inception Architecture for Computer Vision* Inception V3 (top5 error rate 3.5)\n",
    " 4. 2016.02 *Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning* Inception V4 (top5 error rate 3.08)\n",
    " \n",
    "+ **InceptionV2**\n",
    " 学习了VGGNet，使用3x3堆叠卷积代替5x5卷积，提出了**BatchNormalization**，一个有效的正则化方法，可以让大型卷积网络训练速度加快很多倍，准确率也大幅提高，\n",
    " BN用于某层时，会对每一个mini-batch进行标准化处理，使输出规范到N(0,1)的正态分布，减少了InternalConvariateShift（内部神经元分布的改变）。\n",
    " \n",
    " BN论文指出，传统深度学习在训练时，每一层输出分布都在变化，导致训练变得困难，智能用较小的学习率解决。而使用BN后，可以有效解决这个问题，学习速率可以增大很多倍，达到之前的准确率所需迭代次数只有1/14,BN某种意义上起到了正则化作用，因此可以减少Dropout，简化网络结构。\n",
    " \n",
    "+ 使用BN要做的一些调整\n",
    "  - 增大学习率\n",
    "  - 去除Dropout\n",
    "  - 减轻L2正则\n",
    "  - 去除LRN\n",
    "  - 更彻底地对训练样本进行shuffle\n",
    "  - 减少数据增强过程对数据的光学畸变（BN训练更快，每个样本被训练次数更少，因此真实的数据更有帮助）\n",
    "  \n",
    "+ **InceptionV3**\n",
    "   + 引入Factorization into small convolutions思想，将较大二维卷积拆成两个较小的1维卷积。如将7x7卷积拆成1x7和7x1卷积。加速运算节约参数减轻过拟合，论文指出，这种非对称的卷积结构拆分，结果比对称拆为几个相同的卷积核效果更明显，可以处理更多，更丰富的空间特征，增加特征多样性。\n",
    "   ![3_3to1_3and1_3.png](img/3_3to1_3and1_3.png)\n",
    "   + 优化了InceptionModule结构，现在InceptionModule有35x35,17x17,8x8三种不同结构。这些InceptionModule只在网络后部出现。并且除了在InceptionModule中使用分支，还在分支中使用了分支（8x8结构中），可以说是Network in Network in Network。\n",
    "   ![InceptionV3Module.png](img/InceptionV3Module.png)\n",
    "\n",
    "+ **InceptionV4**\n",
    " 结合了微软的ResNet。\n",
    " \n",
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面实现InceptionV3，其网络结构如下表所示\n",
    "![InceptionV3](img/InceptionV3.png)\n",
    "\n",
    "这里使用tf.contrib.slim辅助设计这个网络，只需要少量的代码即可构建好有42层深的InceptionV3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先使用lambda语法定义一个简单的函数，用来产生截断的正态分布函数**trunc_normal**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import math\n",
    "\n",
    "slim = tf.contrib.slim\n",
    "trunc_normal = lambda stddev:tf.truncated_normal_initializer(0.0, stddev)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义函数inception_v3_scope函数，用来生成网络中经常用到的默认的参数。比如卷积的激活函数，权重的初始化方式，标准化器等。\n",
    "+ L2正则的weight_decay默认为0.00004\n",
    "+ 标准差为0.1\n",
    "+ 参数batch_norm_var_collection默认值为moving_vars.\n",
    "\n",
    "接下来定义batch_normalization的参数字典。\n",
    "+ 衰减系数 decay : 0.9997\n",
    "+ epsilon : 0.001\n",
    "+ updates_collections : tf.GraphKeys.UPDATE_OPS\n",
    "+ variables_collections \n",
    "  - beta : None \n",
    "  - gamma : None\n",
    "  - moving_mean : batch_norm_var_collection\n",
    "  - moving_variance : batch_norm_var_collection\n",
    "  \n",
    "之后使用slim.arg_scope函数，这是一个非常有用的工具，它可以给函数的参数自动赋予某些之，例如下面这句：\n",
    "```python\n",
    "    with slim.arg_scope([slim.conv2d, slim.fully_connected],\n",
    "                 weights_regularizer=slim.l2_regularizer(weight_decay))\n",
    "```\n",
    "会对\\[slim.conv2d, slim.fully_connected\\]这两个函数自动赋值，将参数weights_regularizers的值默认设为slim.l2_regularizer(weight_decay),使用了slim.arg_scope就不用每次都重复设置参数了。只需要在有修改时设置。\n",
    "\n",
    "之后，嵌套一个slim.arg_scope,对卷积层生成函数slim.conv2d的几个参数赋予默认值\n",
    "+ 权重初始化器：weights_initializer ： trunc_normal\n",
    "+ 激活函数 ：activation_fn ： ReLU\n",
    "+ 标准化器 ：normalizer_fn ： batch_norm\n",
    "+ 标准化器的参数设置为前面定义的 batch_norm_params\n",
    "\n",
    "最后返回定义好的scope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inception_v3_arg_scope(weight_decay=0.00004, stddev=0.1, batch_norm_var_collection='moving_vars'):\n",
    "    \n",
    "    # 定义batch_normalization 的参数字典\n",
    "    batch_norm_params = {\n",
    "        'decay':0.9997,\n",
    "        'epsilon':0.001,\n",
    "        'updates_collections':tf.GraphKeys.UPDATE_OPS,\n",
    "        'variables_collections':{\n",
    "            'beta':None,\n",
    "            'gamma':None,\n",
    "            'moving_mean':[batch_norm_var_collection],\n",
    "            'moving_variance':[batch_norm_var_collection],\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # 设置conv2d和fully_connected的weights_regularizer默认函数，为卷积层和全连接层的参数设置L2正则化\n",
    "    with slim.arg_scope([slim.conv2d, slim.fully_connected], weights_regularizer=slim.l2_regularizer(weight_decay)):\n",
    "        # 设置卷积操作的权重初始化，激活函数，batch_norm函数，以及batch_norm的默认参数\n",
    "        with slim.arg_scope([slim.conv2d], \n",
    "                            weights_initializer=trunc_normal(stddev=stddev),\n",
    "                            activation_fn = tf.nn.relu,\n",
    "                            normalizer_fn = slim.batch_norm,\n",
    "                            normalizer_params = batch_norm_params) as sc:\n",
    "            return sc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "因为上面实现定义好了slim.conv2d中的各种默认参数，因此下面在使用的时候就会比较简单。只需要一行代码就可以定义一个卷积层。\n",
    "\n",
    "接下来，我们定义inception_v3_base函数，可以用它来生成InceptionV3的网络的卷积部分，参数inputs是输入图片数据的Tensor，scope包含了函数默认参数的环境。定义一个字典end_points, 用来保存某些关键点用来之后使用。\n",
    "\n",
    "我们准备分步骤实现整个网络的框架，首先，我们先实现上面图表中的InceptionModule之前的那些卷积层的操作，我们定义一个函数来实现上面的操作，即上面图表中开始的六个卷积层和一个池化层\n",
    "![conv1](img/inceptionv3conv1.png)\n",
    "我们定义函数Inception_v3_conv_1\n",
    "\n",
    "首先使用slim.arg_scope对slim.conv2d,slim.max_pool2d,slim.avg_pool2d进行设置默认参数，\n",
    "+ 这里使用slim.conv2d创建卷积层，它的参数如下:\n",
    "    1. inputs 输入的Tensor\n",
    "    2. 输出通道数\n",
    "    3. 卷积核尺寸\n",
    "    4. stride 步长\n",
    "    5. padding模式 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inception_v3_conv_1(inputs):\n",
    "    with slim.arg_scope([slim.conv2d,slim.max_pool2d,slim.avg_pool2d], stride=1,padding=\"VALID\"):\n",
    "        net = slim.conv2d(inputs, 32, [3, 3], stride=2, scope=\"Conv2d_1a_3x3\")\n",
    "        net = slim.conv2d(net, 32, [3, 3], scope=\"Conv2d_2a_3x3\")\n",
    "        net = slim.conv2d(net, 64, [3, 3], padding='SAME', scope=\"Conv2d_2b_3x3\")\n",
    "        net = slim.max_pool2d(net, [3, 3], stride=2, scope=\"MaxPool_3a_3x3\")\n",
    "        net = slim.conv2d(net, 80, [1, 1], scope=\"Conv2d_3b_1x1\")\n",
    "        net = slim.conv2d(net, 192, [3, 3], scope=\"Conv2d_4a_3x3\")\n",
    "        net = slim.max_pool2d(net, [3, 3], stride=2, scope=\"MaxPool_5a_3x3\")\n",
    "    return net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面面代码我们可以观察到，在前面几个非InceptionModule的卷积层中，主要使用了3x3的小卷积核，这是充分借鉴了VGGNet的结构。同时InceptionV3论文总也提出了Factorization into small convolutions 思想，利用连个1维卷积模拟大尺寸的2维卷积，减少参数量的同时增加非线性。前面几层卷积层中还有1x1卷积，可低成本跨通道对特征进行组合。\n",
    "另外，卷积层除了第一个的步长是2，其余的都是1，而池化层尺寸是3x3，步长为2的重叠最大池化，这是AlexNet中用过的结构。\n",
    "\n",
    "网络的输入尺寸为299x299x3,在经历3个步长为2的层之后，尺寸缩小为35x35x192,空间尺寸大大降低，但是输出通道增加了很多。这部分代码共有4个卷积层，2个池化层，实现了对输入图片数据的尺寸压缩，并对图片特征进行了抽象。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来是三个InceptionModule组，包含了3个结构类似的InceptionModule，他们结构和上面的6-13的第一幅图有点类似。\n",
    "![modules1](img/modules1.png)\n",
    "\n",
    "#### 下面实现第一个模块组，它包含有三个InceptionModule\n",
    "\n",
    "我们先实现**第一个模块组的第一个InceptionModule**，名称为*Mixed_5b*,同上，我们先使用slim.arg_scope设置所有InceptionModule模块组的参数，所有层步长设为1，padding设为SAME。然后设置这个InceptionModule的variable_scope为Mixed_5b.\n",
    "函数名称设置为inception_module_1_1\n",
    "\n",
    "这个InceptionModule有四个分支，从branch_0到branch_3.\n",
    "1. 第一个分支 64个输出通道的1x1卷积\n",
    "2. 第二个分支 48个输出通道的1x1卷积，链接64个输出通道的5x5卷积\n",
    "3. 第三个分支 64个输出通道的1x1卷积，连接两个96输出通道的3x3卷积\n",
    "4. 第四个分支 3x3的平均池化，链接32个输出通道的1x1卷积\n",
    "\n",
    "最后，使用tf.concat将四个分支的输出合并到一起（在第3个维度合并)，即输出通道上面合并。因为这里所有层的步长都为1，且padding模式为SAME，因此尺寸不会缩小，依然会维持在35x35,最终输出通道数之和为64+64+96+32=256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inception_module1_1(inputs):\n",
    "    with tf.variable_scope(\"Mixed_5b\"):\n",
    "        with tf.variable_scope(\"Branch_0\"):\n",
    "            branch_0 = slim.conv2d(inputs, 64, [1, 1], scope=\"Conv2d_0a_1x1\")\n",
    "        with tf.variable_scope(\"Branch_1\"):\n",
    "            branch_1 = slim.conv2d(inputs, 48, [1, 1], scope=\"Conv2d_0a_1x1\")\n",
    "            branch_1 = slim.conv2d(branch_1, 64, [5, 5], scope=\"Conv2d_0b_5x5\")\n",
    "        with tf.variable_scope(\"Branch_2\"):\n",
    "            branch_2 = slim.conv2d(inputs, 64, [1, 1], scope=\"Conv2d_0a_1x1\")\n",
    "            branch_2 = slim.conv2d(branch_2, 96, [3, 3], scope=\"Conv2d_0b_3x3\")\n",
    "            branch_2 = slim.conv2d(branch_2, 96, [3, 3], scope=\"Conv2d_0c_3x3\")\n",
    "        with tf.variable_scope(\"Branch_3\"):\n",
    "            branch_3 = slim.avg_pool2d(inputs, [3, 3], scope=\"AvgPool_0a_3x3\")\n",
    "            branch_3 = slim.conv2d(branch_3, 32, [1, 1], scope=\"Conv2d_0b_1x1\")\n",
    "    return tf.concat([branch_0, branch_1, branch_2, branch_3], 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**之后实现第一个模块组的第二个InceptionModule（*Mixed_5c*）**。这一个module同样有4个分支，唯一和第一个Module不同的是，第四个分支接的是64输出通道的1x1卷积，之前是32个输出通道，因此，第二个module最终输出尺寸是35x35x288,通道数比之前增加了32个"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inception_module1_2(inputs):\n",
    "    with tf.variable_scope(\"Mixed_5c\"):\n",
    "        with tf.variable_scope(\"Branch_0\"):\n",
    "            branch_0 = slim.conv2d(inputs, 64, [1, 1], scope=\"Conv2d_0a_1x1\")\n",
    "        with tf.variable_scope(\"Branch_1\"):\n",
    "            branch_1 = slim.conv2d(inputs, 48, [1, 1], scope=\"Conv2d_0a_1x1\")\n",
    "            branch_1 = slim.conv2d(branch_1, 64, [5, 5], scope=\"Conv2d_0b_5x5\")\n",
    "        with tf.variable_scope(\"Branch_2\"):\n",
    "            branch_2 = slim.conv2d(inputs, 64, [1, 1], scope=\"Conv2d_0a_1x1\")\n",
    "            branch_2 = slim.conv2d(branch_2, 96, [3, 3], scope=\"Conv2d_0b_3x3\")\n",
    "            branch_2 = slim.conv2d(branch_2, 96, [3, 3], scope=\"Conv2d_0c_3x3\")\n",
    "        with tf.variable_scope(\"Branch_3\"):\n",
    "            branch_3 = slim.avg_pool2d(inputs, [3, 3], scope=\"AvgPool_0a_3x3\")\n",
    "            branch_3 = slim.conv2d(branch_3, 64, [1, 1], scope=\"Conv2d_0b_1x1\")\n",
    "    return tf.concat([branch_0, branch_1, branch_2, branch_3], 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**第一个模块组的第三个InceptionModule（*Mixed_5d*）,和上面第二个Module完全一样**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inception_module1_3(inputs):\n",
    "    with tf.variable_scope(\"Mixed_5d\"):\n",
    "        with tf.variable_scope(\"Branch_0\"):\n",
    "            branch_0 = slim.conv2d(inputs, 64, [1, 1], scope=\"Conv2d_0a_1x1\")\n",
    "        with tf.variable_scope(\"Branch_1\"):\n",
    "            branch_1 = slim.conv2d(inputs, 48, [1, 1], scope=\"Conv2d_0a_1x1\")\n",
    "            branch_1 = slim.conv2d(branch_1, 64, [5, 5], scope=\"Conv2d_0b_5x5\")\n",
    "        with tf.variable_scope(\"Branch_2\"):\n",
    "            branch_2 = slim.conv2d(inputs, 64, [1, 1], scope=\"Conv2d_0a_1x1\")\n",
    "            branch_2 = slim.conv2d(branch_2, 96, [3, 3], scope=\"Conv2d_0b_3x3\")\n",
    "            branch_2 = slim.conv2d(branch_2, 96, [3, 3], scope=\"Conv2d_0c_3x3\")\n",
    "        with tf.variable_scope(\"Branch_3\"):\n",
    "            branch_3 = slim.avg_pool2d(inputs, [3, 3], scope=\"AvgPool_0a_3x3\")\n",
    "            branch_3 = slim.conv2d(branch_3, 64, [1, 1], scope=\"Conv2d_0b_1x1\")\n",
    "    return tf.concat([branch_0, branch_1, branch_2, branch_3], 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "好了，上面的第一个模块组我们已经定义完了\n",
    "\n",
    "#### 接下来定义第二个模块组，它总共有5个InceptionModule\n",
    "其中第二个到第五个InceptionModule非常类似，它的结构如上面的图6-13的第二幅图所示。\n",
    "![modules2.png](img/modules2.png)\n",
    "**第二个模块组的第一个InceptionModule名称为Mixed_6a,它包含有3个分支**\n",
    "+ 第一个分支是一个384输出通道的3x3卷积,这个分支通道数超过了之前的通道数之和，不过步长为2，因此尺寸会被压缩，且Padding模式为VALID，因此图片尺寸缩小为17x17\n",
    "+ 第二个分支是有三层，分别是64输出通道的1x1卷积，两个96输出通道的3x3卷积，最后一层步长为2，Padding为VALID\n",
    "+ 第三个分支是3x3最大池化层，步长为2，padding为VALID\n",
    "最后使用tf.concat在输出通道上合并，最终的输出通道数为384+96+288=768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inception_module2_1(inputs):\n",
    "    with tf.variable_scope(\"Mixed_6a\"):\n",
    "        with tf.variable_scope(\"Branch_0\"):\n",
    "            branch_0 = slim.conv2d(inputs, 384, [3, 3], stride=2, padding=\"VALID\", scope=\"Conv2d_1a_1x1\")\n",
    "        with tf.variable_scope(\"Branch_1\"):\n",
    "            branch_1 = slim.conv2d(inputs, 64, [1, 1], scope=\"Conv2d_0a_1x1\")\n",
    "            branch_1 = slim.conv2d(branch_1, 96, [3, 3], scope=\"Conv2d_0b_3x3\")\n",
    "            branch_1 = slim.conv2d(branch_1, 96, [3, 3], stride=2, padding=\"VALID\", scope=\"Conv2d_1a_1x1\")\n",
    "        with tf.variable_scope(\"Brabch_2\"):\n",
    "            branch_2 = slim.max_pool2d(inputs, [3, 3], stride=2, padding=\"VALID\", scope=\"MaxPool_1a_3x3\")\n",
    "    return tf.concat([branch_0, branch_1, branch_2], 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**第二个模块组的第二个InceptionModule，有四个分支**\n",
    "+ 第一个分支是简单的192输出通道的1x1卷积\n",
    "+ 第二个分支有三个卷积层，分别是（128输出通道1x1）（128输出通道1x7）（192输出通道7x1）\n",
    "+ 第三个分支有五个卷积层，（128-1x1）（128-7x1）（128-1x7）（128-7x1）（192-1x7）\n",
    "+ 第四个分支是3x3平均池化层，链接192-1x1\n",
    "最后合并，输出通道个数为192+192+192+192=768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inception_module2_2(inputs):\n",
    "    with tf.variable_scope(\"Mixed_6b\"):\n",
    "        with tf.variable_scope(\"Branch_0\"):\n",
    "            branch_0 = slim.conv2d(inputs, 192, [1, 1], scope=\"Conv2d_0a_1x1\")\n",
    "        with tf.variable_scope(\"Branch_1\"):\n",
    "            branch_1 = slim.conv2d(inputs, 128, [1, 1], scope=\"Conv2d_0a_1x1\")\n",
    "            branch_1 = slim.conv2d(branch_1, 128, [1, 7], scope=\"Conv2d_0b_1x7\")\n",
    "            branch_1 = slim.conv2d(branch_1, 192, [7, 1], scope=\"Conv2d_0c_7x1\")\n",
    "        with tf.variable_scope(\"Branch_2\"):\n",
    "            branch_2 = slim.conv2d(inputs, 128, [1, 1], scope=\"Conv2d_0a_1x1\")\n",
    "            branch_2 = slim.conv2d(branch_2, 128, [7, 1], scope=\"Conv2d_0b_7x1\")\n",
    "            branch_2 = slim.conv2d(branch_2, 128, [1, 7], scope=\"Conv2d_0c_1x7\")\n",
    "            branch_2 = slim.conv2d(branch_2, 128, [7, 1], scope=\"Conv2d_0d_7x1\")\n",
    "            branch_2 = slim.conv2d(branch_2, 192, [1, 7], scope=\"Conv2d_0e_1x7\")\n",
    "        with tf.variable_scope(\"Branch_3\"):\n",
    "            branch_3 = slim.avg_pool2d(inputs, [3, 3], scope=\"AvgPool_0a_3x3\")\n",
    "            branch_3 = slim.conv2d(branch_3, 192, [1, 1], scope=\"Conv2d_0b_1x1\")\n",
    "    return tf.concat([branch_0, branch_1, branch_2, branch_3], 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**第二个模块组的第三个InceptionModule**\n",
    "\n",
    "和第二个InceptionModule非常相似，只有一个地方不同，第二个分支和第三个分支的前几个卷积层的输出通道不同，从128变成了160,最终输出通道不变\n",
    "\n",
    "需要注意的是，网络每经过一个InceptionModule，即使Tensor尺寸不变，但是特征都相当于被重新精炼了一遍，其中丰富的卷积和非线性化对提升网络性能帮助很大。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inception_module2_3(inputs):\n",
    "    with tf.variable_scope(\"Mixed_6c\"):\n",
    "        with tf.variable_scope(\"Branch_0\"):\n",
    "            branch_0 = slim.conv2d(inputs, 192, [1, 1], scope=\"Conv2d_0a_1x1\")\n",
    "        with tf.variable_scope(\"Branch_1\"):\n",
    "            branch_1 = slim.conv2d(inputs, 160, [1, 1], scope=\"Conv2d_0a_1x1\")\n",
    "            branch_1 = slim.conv2d(branch_1, 160, [1, 7], scope=\"Conv2d_0b_1x7\")\n",
    "            branch_1 = slim.conv2d(branch_1, 192, [7, 1], scope=\"Conv2d_0c_7x1\")\n",
    "        with tf.variable_scope(\"Branch_2\"):\n",
    "            branch_2 = slim.conv2d(inputs, 160, [1, 1], scope=\"Conv2d_0a_1x1\")\n",
    "            branch_2 = slim.conv2d(branch_2, 160, [7, 1], scope=\"Conv2d_0b_7x1\")\n",
    "            branch_2 = slim.conv2d(branch_2, 160, [1, 7], scope=\"Conv2d_0c_1x7\")\n",
    "            branch_2 = slim.conv2d(branch_2, 160, [7, 1], scope=\"Conv2d_0d_7x1\")\n",
    "            branch_2 = slim.conv2d(branch_2, 192, [1, 7], scope=\"Conv2d_0e_1x7\")\n",
    "        with tf.variable_scope(\"Branch_3\"):\n",
    "            branch_3 = slim.avg_pool2d(inputs, [3, 3], scope=\"AvgPool_0a_3x3\")\n",
    "            branch_3 = slim.conv2d(branch_3, 192, [1, 1], scope=\"Conv2d_0b_1x1\")\n",
    "    return tf.concat([branch_0, branch_1, branch_2, branch_3], 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**第二个模块组的第四个InceptionModule**\n",
    "\n",
    "这个InceptionModule和前一个InceptionModule一模一样，目的是通过InceptionModule精心设计的结构增加卷积和非线性，提炼特征。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inception_module2_4(inputs):\n",
    "    with tf.variable_scope(\"Mixed_6d\"):\n",
    "        with tf.variable_scope(\"Branch_0\"):\n",
    "            branch_0 = slim.conv2d(inputs, 192, [1, 1], scope=\"Conv2d_0a_1x1\")\n",
    "        with tf.variable_scope(\"Branch_1\"):\n",
    "            branch_1 = slim.conv2d(inputs, 160, [1, 1], scope=\"Conv2d_0a_1x1\")\n",
    "            branch_1 = slim.conv2d(branch_1, 160, [1, 7], scope=\"Conv2d_0b_1x7\")\n",
    "            branch_1 = slim.conv2d(branch_1, 192, [7, 1], scope=\"Conv2d_0c_7x1\")\n",
    "        with tf.variable_scope(\"Branch_2\"):\n",
    "            branch_2 = slim.conv2d(inputs, 160, [1, 1], scope=\"Conv2d_0a_1x1\")\n",
    "            branch_2 = slim.conv2d(branch_2, 160, [7, 1], scope=\"Conv2d_0b_7x1\")\n",
    "            branch_2 = slim.conv2d(branch_2, 160, [1, 7], scope=\"Conv2d_0c_1x7\")\n",
    "            branch_2 = slim.conv2d(branch_2, 160, [7, 1], scope=\"Conv2d_0d_7x1\")\n",
    "            branch_2 = slim.conv2d(branch_2, 192, [1, 7], scope=\"Conv2d_0e_1x7\")\n",
    "        with tf.variable_scope(\"Branch_3\"):\n",
    "            branch_3 = slim.avg_pool2d(inputs, [3, 3], scope=\"AvgPool_0a_3x3\")\n",
    "            branch_3 = slim.conv2d(branch_3, 192, [1, 1], scope=\"Conv2d_0b_1x1\")\n",
    "    return tf.concat([branch_0, branch_1, branch_2, branch_3], 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**第二个模块组的第五个InceptionModule**\n",
    "\n",
    "这个InceptionModule依然和前面的InceptionModule一模一样，这是第二个模块组的最后一个InceptionModule，因此我们将这个输出存储到end_points中，作为AuxAuxiliary ClassClassifier辅助模型的分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inception_module2_5(inputs, end_points):\n",
    "    with tf.variable_scope(\"Mixed_6e\"):\n",
    "        with tf.variable_scope(\"Branch_0\"):\n",
    "            branch_0 = slim.conv2d(inputs, 192, [1, 1], scope=\"Conv2d_0a_1x1\")\n",
    "        with tf.variable_scope(\"Branch_1\"):\n",
    "            branch_1 = slim.conv2d(inputs, 160, [1, 1], scope=\"Conv2d_0a_1x1\")\n",
    "            branch_1 = slim.conv2d(branch_1, 160, [1, 7], scope=\"Conv2d_0b_1x7\")\n",
    "            branch_1 = slim.conv2d(branch_1, 192, [7, 1], scope=\"Conv2d_0c_7x1\")\n",
    "        with tf.variable_scope(\"Branch_2\"):\n",
    "            branch_2 = slim.conv2d(inputs, 160, [1, 1], scope=\"Conv2d_0a_1x1\")\n",
    "            branch_2 = slim.conv2d(branch_2, 160, [7, 1], scope=\"Conv2d_0b_7x1\")\n",
    "            branch_2 = slim.conv2d(branch_2, 160, [1, 7], scope=\"Conv2d_0c_1x7\")\n",
    "            branch_2 = slim.conv2d(branch_2, 160, [7, 1], scope=\"Conv2d_0d_7x1\")\n",
    "            branch_2 = slim.conv2d(branch_2, 192, [1, 7], scope=\"Conv2d_0e_1x7\")\n",
    "        with tf.variable_scope(\"Branch_3\"):\n",
    "            branch_3 = slim.avg_pool2d(inputs, [3, 3], scope=\"AvgPool_0a_3x3\")\n",
    "            branch_3 = slim.conv2d(branch_3, 192, [1, 1], scope=\"Conv2d_0b_1x1\")\n",
    "    net = tf.concat([branch_0, branch_1, branch_2, branch_3], 3)\n",
    "    end_points['Mixed_6e'] = net\n",
    "    return net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 最后定义第三个模块组\n",
    "第三个模块组包含3个InceptionModule，其后两个InceptionModule结构非常类似，他们结构如6-13的第三幅图所示。\n",
    "![module3](img/module3.png)\n",
    "\n",
    "**第三个模块组的第一个InceptionModule**有三个分支\n",
    "+ 第一个分支 （192-1x1）（320-3x3步长为2，padding为VALID）\n",
    "+ 第二个分支 （192-1x1）（192-1x7）（192-7x1）（192-3x3步长2,padding为VALID）\n",
    "+ 第三个分支 （3x3最大池化层，步长2， padding为VALID）\n",
    "\n",
    "最终的输出通道数为320+192+768=1280,输出尺寸下降到了8x8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inception_module3_1(inputs):\n",
    "    with tf.variable_scope(\"Mixed_7a\"):\n",
    "        with tf.variable_scope(\"Branch_0\"):\n",
    "            branch_0 = slim.conv2d(inputs, 192, [1, 1], scope=\"Conv2d_0a_1x1\")\n",
    "            branch_0 = slim.conv2d(branch_0, 320, [3, 3], stride=2, padding=\"VALID\", scope=\"Conv2d_1a_3x3\")\n",
    "        with tf.variable_scope(\"Branch_1\"):\n",
    "            branch_1 = slim.conv2d(inputs, 192, [1, 1], scope=\"Conv2d_0a_1x1\")\n",
    "            branch_1 = slim.conv2d(branch_1, 192, [1, 7], scope=\"Conv2d_0b_1x7\")\n",
    "            branch_1 = slim.conv2d(branch_1, 192, [7, 1], scope=\"Conv2d_0c_7x1\")\n",
    "            branch_1 = slim.conv2d(branch_1, 192, [3, 3], stride=2, padding=\"VALID\",scope=\"Conv2d_1a_3x3\")\n",
    "        with tf.variable_scope(\"Branch_2\"):\n",
    "            branch_2 = slim.max_pool2d(inputs, [3, 3], stride=2, padding=\"VALID\", scope=\"MaxPool_1a_3x3\")\n",
    "    return tf.concat([branch_0, branch_1, branch_2], 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**第三个模块组的第二个InceptionModule**有四个分支\n",
    "+ 第一个分支 （320-1x1）\n",
    "+ 第二个分支 （384-1x1）（分成两个分支（384-1x3）（384-3x1）合并）\n",
    "+ 第三个分支 （448-1x1）（384-3x3）（拆成两个分支（384-1x3）（384-3x1）合并）\n",
    "+ 第四个分支 （3x3平均池化层）（192-1x1）\n",
    "\n",
    "合并，最终输出通道数为 320+（384+384）+（384+384）+192=2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inception_module3_2(inputs):\n",
    "    with tf.variable_scope(\"Mixed_7b\"):\n",
    "        with tf.variable_scope(\"Branch_0\"):\n",
    "            branch_0 = slim.conv2d(inputs, 320, [1, 1], scope=\"Conv2d_0a_1x1\")\n",
    "        with tf.variable_scope(\"Branch_1\"):\n",
    "            branch_1 = slim.conv2d(inputs, 384, [1, 1], scope=\"Conv2d_0a_1x1\")\n",
    "            branch_1 = tf.concat([\n",
    "                slim.conv2d(branch_1, 384, [1, 3], scope=\"Conv2d_0b_1x3\"),\n",
    "                slim.conv2d(branch_1, 384, [3, 1], scope=\"Conv2d_0b_3x1\")\n",
    "            ], 3)\n",
    "        with tf.variable_scope(\"Branch_2\"):\n",
    "            branch_2 = slim.conv2d(inputs, 448, [1, 1], scope=\"Conv2d_0a_1x1\")\n",
    "            branch_2 = slim.conv2d(branch_2, 384, [3, 3], scope=\"Conv2d_0b_3x3\")\n",
    "            branch_2 = tf.concat([\n",
    "                slim.conv2d(branch_2, 384, [1, 3], scope=\"Conv2d_0c_1x3\"),\n",
    "                slim.conv2d(branch_2, 384, [3, 1], scope=\"Conv2d_0d_3x1\")\n",
    "            ], 3)\n",
    "        with tf.variable_scope(\"Branch3\"):\n",
    "            branch_3 = slim.avg_pool2d(inputs, [3, 3], scope=\"AvgPool_0a_3x3\")\n",
    "            branch_3 = slim.conv2d(branch_3, 192, [1, 1], scope=\"Conv2d_0b_1x1\")\n",
    "    return tf.concat([branch_0, branch_1, branch_2, branch_3], 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**第三个模块组最后一个InceptionModule和前面的InceptionModule一模一样**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inception_module3_3(inputs):\n",
    "    with tf.variable_scope(\"Mixed_7c\"):\n",
    "        with tf.variable_scope(\"Branch_0\"):\n",
    "            branch_0 = slim.conv2d(inputs, 320, [1, 1], scope=\"Conv2d_0a_1x1\")\n",
    "        with tf.variable_scope(\"Branch_1\"):\n",
    "            branch_1 = slim.conv2d(inputs, 384, [1, 1], scope=\"Conv2d_0a_1x1\")\n",
    "            branch_1 = tf.concat([\n",
    "                slim.conv2d(branch_1, 384, [1, 3], scope=\"Conv2d_0b_1x3\"),\n",
    "                slim.conv2d(branch_1, 384, [3, 1], scope=\"Conv2d_0b_3x1\")\n",
    "            ], 3)\n",
    "        with tf.variable_scope(\"Branch_2\"):\n",
    "            branch_2 = slim.conv2d(inputs, 448, [1, 1], scope=\"Conv2d_0a_1x1\")\n",
    "            branch_2 = slim.conv2d(branch_2, 384, [3, 3], scope=\"Conv2d_0b_3x3\")\n",
    "            branch_2 = tf.concat([\n",
    "                slim.conv2d(branch_2, 384, [1, 3], scope=\"Conv2d_0c_1x3\"),\n",
    "                slim.conv2d(branch_2, 384, [3, 1], scope=\"Conv2d_0d_3x1\")\n",
    "            ], 3)\n",
    "        with tf.variable_scope(\"Branch3\"):\n",
    "            branch_3 = slim.avg_pool2d(inputs, [3, 3], scope=\"AvgPool_0a_3x3\")\n",
    "            branch_3 = slim.conv2d(branch_3, 192, [1, 1], scope=\"Conv2d_0b_1x1\")\n",
    "    return tf.concat([branch_0, branch_1, branch_2, branch_3], 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最后，我们将上面定义好的各个模块的函数组合到一起"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inception_v3_base(inputs, scope=None):\n",
    "    end_points = {}\n",
    "    with tf.variable_scope(scope, \"InceptionV3\", [inputs]):\n",
    "        \n",
    "        # 非InceptionModule处理\n",
    "        net = inception_v3_conv_1(inputs)\n",
    "        \n",
    "        with slim.arg_scope([slim.conv2d, slim.max_pool2d, slim.avg_pool2d],stride=1, padding=\"SAME\"):\n",
    "            \n",
    "            # 第一个模块组的处理\n",
    "            net = inception_module1_1(net)\n",
    "            net = inception_module1_2(net)\n",
    "            net = inception_module1_3(net)\n",
    "            \n",
    "            # 第二个模块组的处理\n",
    "            net = inception_module2_1(net)\n",
    "            net = inception_module2_2(net)\n",
    "            net = inception_module2_3(net)\n",
    "            net = inception_module2_4(net)\n",
    "            net = inception_module2_5(net, end_points)\n",
    "            \n",
    "            # 第三个模块组的处理\n",
    "            net = inception_module3_1(net)\n",
    "            net = inception_module3_2(net)\n",
    "            net = inception_module3_3(net)\n",
    "        return net, end_points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "至此，InceptionV3网络的核心部分（卷积层部分）就完成了。上面的结构中，首先是5个卷积层和2个池化层交替的普通结构，然后是3个InceptionModule模块组。\n",
    "\n",
    "设计InceptionNet的一个重要原则是，图片尺寸是不断缩小的，从299x299经过5个步长为2的卷积层或池化层后，缩小为8x8，同时输出通道不断增加，从一开始的3到最后的2048。\n",
    "\n",
    "从这里可以看出，每一层卷积，池化或者Inception模块组目的都是将空间结构简化，同时将空间信息转化为高阶抽象的特征信息。即将空间的维度转换为通道维度。\n",
    "\n",
    "**可以发现，InceptionModule一般有四个分支：**\n",
    "1. 第一个分支一般是1x1卷积（简单抽象特征）\n",
    "2. 第二个分支一般是1x1卷积再接分解后的1xn和nx1卷积（复杂特征抽象）\n",
    "3. 第三个分支和第二个分支类似但是一般更深一些（复杂特征抽象）\n",
    "4. 第四个分支一般具有最大池化或平均池化（简化结构池化层）\n",
    "\n",
    "四种不同程度的特征抽象和变换有选择的保留不同层次的高阶特征，这样可以最大程度的丰富网络的表达能力。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来。实现InceptionV3的最后一个部分，"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inception_v3(inputs, num_classes=1000, is_training=True, dropout_keep_prob=0.8, \n",
    "                 prediction_fn=slim.softmax, spatial_squeeze=True, reuse=None, scope=\"InceptionV3\"):\n",
    "    \n",
    "    with tf.variable_scope(scope, \"InceptionV3\", [inputs, num_classes], reuse=reuse) as scope:\n",
    "        \n",
    "        with slim.arg_scope([slim.batch_norm, slim.dropout], is_training=is_training):\n",
    "            net, end_points = inception_v3_base(inputs, scope=scope)\n",
    "        \n",
    "        with slim.arg_scope([slim.conv2d, slim.max_pool2d, slim.avg_pool2d],stride=1,padding=\"SAME\"):\n",
    "            aux_logits = end_points['Mixed_6e']\n",
    "            \n",
    "            with tf.variable_scope(\"AuxLogits\"):\n",
    "                aux_logits = slim.avg_pool2d(aux_logits, [5, 5], stride=3, padding=\"VALID\", scope=\"AvgPool_1a_5x5\")\n",
    "                aux_logits = slim.conv2d(aux_logits, 128, [1, 1], scope=\"Conv2d_1b_1x1\")\n",
    "                aux_logits = slim.conv2d(aux_logits, 768, [5, 5], \n",
    "                                         weights_initializer=trunc_normal(0.01),padding=\"VALID\", scope=\"Conv2d_2a_5x5\")\n",
    "                aux_logits = slim.conv2d(aux_logits, num_classes, [1, 1], \n",
    "                                         activation_fn=None, normalizer_fn=None,\n",
    "                                         weights_initializer=trunc_normal(0.001),scope=\"Conv2d_2b_1x1\")\n",
    "                if spatial_squeeze:\n",
    "                    aux_logits = tf.squeeze(aux_logits, [1, 2], name=\"SpatialSqueeze\")\n",
    "                end_points[\"AuxLogits\"] = aux_logits\n",
    "            \n",
    "            with tf.variable_scope(\"Logits\"):\n",
    "                net = slim.avg_pool2d(net, [8, 8], padding=\"VALID\", scope=\"AvgPool_1a_8x8\")\n",
    "                net = slim.dropout(net, keep_prob=dropout_keep_prob, scope=\"Dropout_1b\")\n",
    "                end_points[\"PreLogits\"] = net\n",
    "                logits = slim.conv2d(net, num_classes, [1, 1], \n",
    "                                     activation_fn=None, normalizer_fn=None,scope=\"Conv2d_1c_1x1\")\n",
    "                if spatial_squeeze:\n",
    "                    logits = tf.squeeze(logits, [1, 2], name=\"SpatialSqueeze\")\n",
    "            end_points[\"Logits\"] = logits\n",
    "            end_points[\"Predictions\"] = prediction_fn(logits, scope=\"Predictions\")\n",
    "        return logits, end_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_tensorflow_run(session, target, info_string):\n",
    "    print(\"start time is :%s\" %(datetime.now()))\n",
    "    durations = []\n",
    "    steps = []\n",
    "    num_steps_burn_in = 10\n",
    "    total_duration = 0.\n",
    "    total_duration_squared = 0.\n",
    "    for i in range(num_batches + num_steps_burn_in):\n",
    "        start_time = time.time()\n",
    "        _ = session.run(target)\n",
    "        duration = time.time() - start_time\n",
    "        if i >= num_steps_burn_in:\n",
    "            #print('%s: step %d, duration = %.3f' % (datetime.now(), i-num_steps_burn_in, duration))\n",
    "            durations.append(duration)\n",
    "            steps.append(i - num_steps_burn_in)\n",
    "            total_duration += duration\n",
    "            total_duration_squared += duration * duration\n",
    "    mn = total_duration / num_batches\n",
    "    vr = total_duration_squared / num_batches - mn * mn\n",
    "    sd = math.sqrt(vr)\n",
    "    plt.plot(steps, durations)\n",
    "    plt.xlabel(\"setp\")\n",
    "    plt.ylabel(\"duration/sec\")\n",
    "    plt.title(info_string)\n",
    "    plt.show()\n",
    "    print(\"%s:%s across %d steps, %.3f +/- %.3f sec / batch\" %(datetime.now(), info_string, num_batches, mn, sd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start time is :2018-02-14 19:15:10.921615\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x19279279e48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-02-14 20:00:29.793116:Forward across 100 steps, 24.936 +/- 1.175 sec / batch\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "height, width = 299, 299\n",
    "inputs = tf.random_uniform((batch_size, height, width, 3))\n",
    "with slim.arg_scope(inception_v3_arg_scope()):\n",
    "    logits, end_points = inception_v3(inputs, is_training=True)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "num_batches = 100\n",
    "time_tensorflow_run(sess, logits, \"Forward\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
